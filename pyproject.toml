[project]
name = "structured-evals"
version = "0.1.0"
description = "Evaluation of LLMs' structured outputs"
readme = "README.md"
authors = [
    { name = "jakub.binkowski", email = "jakub.binkowski@pwr.edu.pl" }
]
requires-python = ">=3.12"
dependencies = [
    "langchain>=0.3.27",
    "langchain-community>=0.3.27",
    "langchain-google-genai>=2.1.9",
    "langchain-openai>=0.3.30",
    "loguru>=0.7.3",
    "numpy>=2.3.2",
    "python-dotenv>=1.1.1",
    "pyyaml>=6.0.2",
    "tabulate>=0.9.0",
    "tenacity>=9.1.2",
    "torchmetrics>=1.8.1",
]

[build-system]
requires = ["uv_build>=0.8.11,<0.9.0"]
build-backend = "uv_build"

[dependency-groups]
dev = [
    "coverage>=7.10.3",
    "mypy>=1.17.1",
    "pdbpp>=0.11.7",
    "pip>=25.2",
    "pre-commit>=4.3.0",
    "pytest>=8.4.1",
    "ruff>=0.12.9",
]

[tool.ruff]
line-length = 100

[tool.ruff.lint]
select = ["E4", "E7", "E9", "F", "I"]

[tool.mypy]
ignore_missing_imports = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true

[tool.coverage.run]
source_pkgs = ["structured_evals", "tests"]
branch = true
parallel = false
omit = []

[tool.coverage.paths]
structured_evals = ["structured_evals"]
tests = ["tests"]

[tool.coverage.report]
show_missing = true
exclude_lines = [
    "no cov",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
]
